{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "# 3 столбца - id, text, author\n",
    "df_train.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "def tokenize_stem(file_text):\n",
    "    #firstly let's apply nltk tokenization\n",
    "    file_text = file_text.translate(remove_digits)\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(file_text)\n",
    "    except:\n",
    "        nltk.download('punkt')\n",
    "        tokens = nltk.word_tokenize(file_text)\n",
    "        \n",
    "\n",
    "    #let's delete punctuation symbols\n",
    "    tokens = [i for i in tokens if ( i not in string.punctuation )]\n",
    "\n",
    "    #deleting stop_words\n",
    "    try:\n",
    "        stop_words = stopwords.words('english')\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = stopwords.words('english')\n",
    "    tokens = [i for i in tokens if ( i not in stop_words )]\n",
    "\n",
    "    #cleaning words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    tokens = [stemmer.stem(i) for i in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[this, process, howev, afford, mean, ascertain...</td>\n",
       "      <td>this process howev afford mean ascertain dimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n",
       "      <td>it never occur fumbl might mere mistak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n",
       "      <td>in left hand gold snuff box caper hill cut man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [this, process, howev, afford, mean, ascertain...   \n",
       "1     [it, never, occur, fumbl, might, mere, mistak]   \n",
       "2  [in, left, hand, gold, snuff, box, caper, hill...   \n",
       "\n",
       "                                 cleaned_text_string  \n",
       "0  this process howev afford mean ascertain dimen...  \n",
       "1             it never occur fumbl might mere mistak  \n",
       "2  in left hand gold snuff box caper hill cut man...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cleaned_text'] = df_train.text.apply(tokenize_stem)\n",
    "df_train['cleaned_text_string'] = df_train.cleaned_text.apply(' '.join)\n",
    "df_train.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_string</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[this, process, howev, afford, mean, ascertain...</td>\n",
       "      <td>this process howev afford mean ascertain dimen...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n",
       "      <td>it never occur fumbl might mere mistak</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n",
       "      <td>in left hand gold snuff box caper hill cut man...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [this, process, howev, afford, mean, ascertain...   \n",
       "1     [it, never, occur, fumbl, might, mere, mistak]   \n",
       "2  [in, left, hand, gold, snuff, box, caper, hill...   \n",
       "\n",
       "                                 cleaned_text_string  length  \n",
       "0  this process howev afford mean ascertain dimen...     145  \n",
       "1             it never occur fumbl might mere mistak      38  \n",
       "2  in left hand gold snuff box caper hill cut man...     116  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['length']=df_train['cleaned_text_string'].apply(len)\n",
    "df_train.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93.395386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>51.075096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>561.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  5635.000000\n",
       "mean     93.395386\n",
       "std      51.075096\n",
       "min       7.000000\n",
       "25%      58.000000\n",
       "50%      85.000000\n",
       "75%     118.000000\n",
       "max     561.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpl=df_train[df_train['author']=='HPL']\n",
    "df_hpl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.543165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.100183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>925.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  7900.000000\n",
       "mean     81.543165\n",
       "std      60.100183\n",
       "min       5.000000\n",
       "25%      40.000000\n",
       "50%      66.000000\n",
       "75%     106.000000\n",
       "max     925.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eap=df_train[df_train['author']=='EAP']\n",
    "df_eap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6044.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>86.124586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>71.976281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2715.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  6044.000000\n",
       "mean     86.124586\n",
       "std      71.976281\n",
       "min       4.000000\n",
       "25%      48.000000\n",
       "50%      74.000000\n",
       "75%     108.000000\n",
       "max    2715.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mws=df_train[df_train['author']=='MWS']\n",
    "df_mws.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# как мы будем эту штуку правильнее делать (возможно это жуткий костыль), я хз\n",
    "# сначала создаем словарь где ключ - уникальное слово, а значение - его порядковый номер\n",
    "# затем создаем разреженную матрицу, которую заполняем в зависимости от порядковых номеров \n",
    "word_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#делаю сет со всеми словами\n",
    "# и сразу заготовку под шапку(потом увидишь зачем)\n",
    "counter = 0\n",
    "head = []\n",
    "\n",
    "for wordlist in df_train['cleaned_text']:\n",
    "    for word in wordlist:\n",
    "        if word not in word_dict:\n",
    "            head.append(word)\n",
    "            word_dict[word] = counter\n",
    "            counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15230"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# видоизменять колонки в pandas руками по одному значению в строке или столбце - очень плохая идея\n",
    "# колонка это numpy.ndarray, а значит при каждой итерации она будет пересоздаваться\n",
    "# что угробит производительность\n",
    "# делаем значит так. считаем где сколько и где встречались отдельные слова, затем создаем строку за строкой для \n",
    "# каждого предложения\n",
    "\n",
    "list_of_lists = []\n",
    "\n",
    "for wordlist in df_train['cleaned_text']:\n",
    "    row = [0 for i in range(len(word_dict))]\n",
    "    for word in wordlist:\n",
    "        row[word_dict[word]] += 1\n",
    "    list_of_lists.append(csr_matrix(row))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15230 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... и для того чтобы посмотреть встречаемость того или иного слова по авторам добавим такую колонку\n",
    "\n",
    "count_frame = pd.DataFrame(list_of_lists)\n",
    "count_frame['author'] = df_train['author']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)\\t1\\n  (0, 1)\\t1\\n  (0, 2)\\t1\\n  (0, 3...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 9)\\t1\\n  (0, 23)\\t1\\n  (0, 24)\\t1\\n  (0,...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 29)\\t1\\n  (0, 30)\\t1\\n  (0, 31)\\t1\\n  (0...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 48)\\t1\\n  (0, 49)\\t1\\n  (0, 50)\\t1\\n  (0...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 32)\\t1\\n  (0, 52)\\t1\\n  (0, 70)\\t1\\n  (0...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0 author\n",
       "0    (0, 0)\\t1\\n  (0, 1)\\t1\\n  (0, 2)\\t1\\n  (0, 3...    EAP\n",
       "1    (0, 9)\\t1\\n  (0, 23)\\t1\\n  (0, 24)\\t1\\n  (0,...    HPL\n",
       "2    (0, 29)\\t1\\n  (0, 30)\\t1\\n  (0, 31)\\t1\\n  (0...    EAP\n",
       "3    (0, 48)\\t1\\n  (0, 49)\\t1\\n  (0, 50)\\t1\\n  (0...    MWS\n",
       "4    (0, 32)\\t1\\n  (0, 52)\\t1\\n  (0, 70)\\t1\\n  (0...    HPL"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# выглядить довольно отстойно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_string</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[this, process, howev, afford, mean, ascertain...</td>\n",
       "      <td>this process howev afford mean ascertain dimen...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n",
       "      <td>it never occur fumbl might mere mistak</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n",
       "      <td>in left hand gold snuff box caper hill cut man...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[how, love, spring, as, look, windsor, terrac,...</td>\n",
       "      <td>how love spring as look windsor terrac sixteen...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[find, noth, els, even, gold, superintend, aba...</td>\n",
       "      <td>find noth els even gold superintend abandon at...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [this, process, howev, afford, mean, ascertain...   \n",
       "1     [it, never, occur, fumbl, might, mere, mistak]   \n",
       "2  [in, left, hand, gold, snuff, box, caper, hill...   \n",
       "3  [how, love, spring, as, look, windsor, terrac,...   \n",
       "4  [find, noth, els, even, gold, superintend, aba...   \n",
       "\n",
       "                                 cleaned_text_string  length  \n",
       "0  this process howev afford mean ascertain dimen...     145  \n",
       "1             it never occur fumbl might mere mistak      38  \n",
       "2  in left hand gold snuff box caper hill cut man...     116  \n",
       "3  how love spring as look windsor terrac sixteen...     144  \n",
       "4  find noth els even gold superintend abandon at...     102  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# попробуем не просто tf-idf посчитать, а слить все предложения для каждого писателя в один большой массив слов\n",
    "# и после этого дальше считаем tf-idf для каждого слова при этом только для трех документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_documents_authors = ['', '', '']\n",
    "\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    \n",
    "    if row['author'] == 'EAP':\n",
    "        raw_documents_authors[0] += row['cleaned_text_string'] + ' '\n",
    "    elif row['author'] == 'HPL':\n",
    "        raw_documents_authors[1] += row['cleaned_text_string'] + ' '\n",
    "    else:\n",
    "        raw_documents_authors[2] += row['cleaned_text_string'] + ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим уникальные слова, не встречающиеся у других писателей\n",
    "\n",
    "eap_only = set(raw_documents_authors[0].split(' ')) - set(raw_documents_authors[1].split(' ')) - set(raw_documents_authors[2].split(' '))\n",
    "hpl_only = set(raw_documents_authors[1].split(' ')) - set(raw_documents_authors[0].split(' ')) - set(raw_documents_authors[2].split(' '))\n",
    "msh_only = set(raw_documents_authors[2].split(' ')) - set(raw_documents_authors[0].split(' ')) - set(raw_documents_authors[1].split(' '))\n",
    "\n",
    "unique_words = eap_only.union(hpl_only).union(msh_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8149"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word')\n",
    "idf_matrix =  tf.fit_transform(raw_documents_authors)\n",
    "feature_names = tf.get_feature_names()\n",
    "# dictionary_word = dict(zip(feature_names, idf_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[matrix([[ 0.00053369,  0.00053369,  0.00106738, ...,  0.00053369,\n",
      "          0.        ,  0.        ]]), matrix([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.00135189,  0.00067595]]), matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])]\n"
     ]
    }
   ],
   "source": [
    "dense_idf = [i.todense() for i in idf_matrix]\n",
    "print(dense_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(dense_idf[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_weighted_term = []\n",
    "\n",
    "eap_dense_list = dense_idf[0].tolist()[0]\n",
    "hpl_dense_list = dense_idf[1].tolist()[0]\n",
    "mws_dense_list = dense_idf[2].tolist()[0]\n",
    "\n",
    "for inum, i in enumerate(eap_dense_list):\n",
    "    max_weighted_term.append(max(hpl_dense_list[inum], mws_dense_list[inum], \n",
    "                             i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15120\n",
      "15120\n"
     ]
    }
   ],
   "source": [
    "print(len(max_weighted_term))\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_tf_dict = dict(zip(feature_names, max_weighted_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# найдем теперь топ 20 слов по tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: вот это причесать и отавтоматизировать\n",
    "\n",
    "def extract_top_words(tfidfdict, numwrd):\n",
    "\n",
    "    top_word_dict, min_value, min_key = {}, 99, ''\n",
    "    \n",
    "\n",
    "    for k, v in max_tf_dict.items():\n",
    "        # print(top_word_dict.values())\n",
    "        # print(v)\n",
    "        if k not in unique_words:\n",
    "        \n",
    "            if len(top_word_dict) < numwrd:\n",
    "                top_word_dict[k] = v\n",
    "                if v <= min_value:\n",
    "                    min_key = k\n",
    "            else:\n",
    "                # print(v, min(list(top_word_dict.values())))\n",
    "                if v > min(list(top_word_dict.values())):\n",
    "\n",
    "                    min_value = min(top_word_dict.values())\n",
    "\n",
    "                    for ky, va in top_word_dict.items():\n",
    "                        if va == min_value:\n",
    "                            min_key = ky\n",
    "\n",
    "                    top_word_dict.pop(min_key)\n",
    "                    top_word_dict[k] = v\n",
    "                \n",
    "    return top_word_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# так не годится. нужно дополнительно почтистить стоп слова\n",
    "\n",
    "\n",
    "stop_words = get_stop_words('english')\n",
    "\n",
    "max_tf_dict_clone = max_tf_dict\n",
    "\n",
    "for wrd in stop_words:\n",
    "    try:\n",
    "        max_tf_dict_clone.pop(wrd)\n",
    "    except KeyError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_top_words_dict = extract_top_words(max_tf_dict_clone, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'came': 0.08623264906148835,\n",
       " 'day': 0.10905692297089824,\n",
       " 'even': 0.11284362168516554,\n",
       " 'everi': 0.08823008004242809,\n",
       " 'eye': 0.10829958322804477,\n",
       " 'feel': 0.10186219541379037,\n",
       " 'heart': 0.10981426271375169,\n",
       " 'hope': 0.08633673068529443,\n",
       " 'hous': 0.10260088337408568,\n",
       " 'life': 0.12647573705652781,\n",
       " 'like': 0.11817066723240997,\n",
       " 'littl': 0.08731231706628834,\n",
       " 'love': 0.16131336522778697,\n",
       " 'man': 0.11178306359822565,\n",
       " 'might': 0.10186219541379037,\n",
       " 'night': 0.1069923608725874,\n",
       " 'old': 0.15649628903751592,\n",
       " 'one': 0.21181905078897387,\n",
       " 'raymond': 0.13165372929973168,\n",
       " 'said': 0.11221366381082544,\n",
       " 'saw': 0.09421715360421876,\n",
       " 'say': 0.10527911155285308,\n",
       " 'seem': 0.1285505231379595,\n",
       " 'thing': 0.17286452335011324,\n",
       " 'though': 0.09341870314994571,\n",
       " 'thought': 0.08823008004242809,\n",
       " 'time': 0.11218228882536217,\n",
       " 'upon': 0.3230870938373485,\n",
       " 'us': 0.10299820502807056,\n",
       " 'yet': 0.12041701911370013}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_top_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# будем считать что эти слова влияют на то автор это или нет"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
